#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬ï¼šæµ‹è¯•ä¼˜åŒ–åçš„é‡å¤å›¾ç‰‡åˆ é™¤ç®—æ³•
"""

import time
import numpy as np
from RemoveDuplicationThread import ImageHasher

def test_performance():
    """æµ‹è¯•ç®—æ³•æ€§èƒ½"""
    print("=" * 60)
    print("é‡å¤å›¾ç‰‡åˆ é™¤ç®—æ³•æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    hasher = ImageHasher()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    num_images = 1000
    hash_size = 64  # 8x8 å“ˆå¸Œ
    
    # åˆ›å»ºä¸€äº›ç›¸ä¼¼çš„å“ˆå¸Œå€¼
    test_hashes = {}
    base_hash = np.random.choice([True, False], size=hash_size)
    
    for i in range(num_images):
        # åˆ›å»ºç›¸ä¼¼çš„å“ˆå¸Œï¼ˆå¤§éƒ¨åˆ†ä½ç›¸åŒï¼Œå°‘é‡ä½ä¸åŒï¼‰
        if i % 10 == 0:  # æ¯10å¼ å›¾ç‰‡åˆ›å»ºä¸€ä¸ªæ–°çš„åŸºç¡€å“ˆå¸Œ
            base_hash = np.random.choice([True, False], size=hash_size)
        
        # æ·»åŠ ä¸€äº›éšæœºå·®å¼‚
        modified_hash = base_hash.copy()
        num_changes = np.random.randint(0, 5)  # 0-4ä½å·®å¼‚
        change_indices = np.random.choice(hash_size, num_changes, replace=False)
        for idx in change_indices:
            modified_hash[idx] = not modified_hash[idx]
        
        test_hashes[f"image_{i}.jpg"] = modified_hash
    
    print(f"ç”Ÿæˆ {len(test_hashes)} ä¸ªæµ‹è¯•å“ˆå¸Œå€¼")
    
    # æµ‹è¯•æ—§ç®—æ³•ï¼ˆæš´åŠ›å¯¹æ¯”ï¼‰
    print("\næµ‹è¯•æ—§ç®—æ³•ï¼ˆæš´åŠ›å¯¹æ¯”ï¼‰...")
    start_time = time.time()
    
    groups_old = {}
    remaining_paths = set(test_hashes.keys())
    group_id = 0
    threshold = 5
    
    while remaining_paths:
        seed_path = remaining_paths.pop()
        groups_old[group_id] = [seed_path]
        seed_hash = test_hashes[seed_path]
        
        to_remove = []
        for path in list(remaining_paths):
            distance = hasher.hamming_distance(seed_hash, test_hashes[path])
            if distance <= threshold:
                groups_old[group_id].append(path)
                to_remove.append(path)
        
        for path in to_remove:
            remaining_paths.discard(path)
        
        group_id += 1
        
        # è¿›åº¦æ˜¾ç¤º
        if group_id % 100 == 0:
            elapsed = time.time() - start_time
            print(f"  å·²å¤„ç† {group_id} ç»„ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    old_time = time.time() - start_time
    print(f"æ—§ç®—æ³•å®Œæˆï¼Œè€—æ—¶: {old_time:.2f}ç§’")
    print(f"æ‰¾åˆ° {len(groups_old)} ä¸ªå›¾ç‰‡ç»„")
    
    # æµ‹è¯•æ–°ç®—æ³•ï¼ˆå“ˆå¸Œæ¡¶ä¼˜åŒ–ï¼‰
    print("\næµ‹è¯•æ–°ç®—æ³•ï¼ˆå“ˆå¸Œæ¡¶ä¼˜åŒ–ï¼‰...")
    start_time = time.time()
    
    groups_new = {}
    hash_buckets = {}
    
    # å°†å“ˆå¸Œå€¼åˆ†ç»„åˆ°æ¡¶ä¸­
    for path, hash_bits in test_hashes.items():
        hash_int = hasher.hash_to_int(hash_bits)
        if hash_int not in hash_buckets:
            hash_buckets[hash_int] = []
        hash_buckets[hash_int].append(path)
    
    # å…ˆå¤„ç†å®Œå…¨ç›¸åŒçš„å›¾ç‰‡
    group_id = 0
    for hash_int, paths in list(hash_buckets.items()):
        if len(paths) > 1:
            groups_new[group_id] = paths
            group_id += 1
            del hash_buckets[hash_int]
    
    # å¤„ç†ç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒçš„å›¾ç‰‡
    remaining_hashes = list(hash_buckets.keys())
    
    for i, hash1_int in enumerate(remaining_hashes):
        paths1 = hash_buckets.get(hash1_int, [])
        if not paths1:
            continue
        
        hash1_bits = test_hashes[paths1[0]]
        
        for j in range(i + 1, len(remaining_hashes)):
            hash2_int = remaining_hashes[j]
            paths2 = hash_buckets.get(hash2_int, [])
            if not paths2:
                continue
            
            hash2_bits = test_hashes[paths2[0]]
            distance = hasher.hamming_distance(hash1_bits, hash2_bits)
            
            if distance <= threshold:
                if group_id not in groups_new:
                    groups_new[group_id] = paths1.copy()
                groups_new[group_id].extend(paths2)
                hash_buckets[hash2_int] = []
        
        # è¿›åº¦æ˜¾ç¤º
        if group_id % 100 == 0:
            elapsed = time.time() - start_time
            print(f"  å·²å¤„ç† {group_id} ç»„ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    # æ·»åŠ å‰©ä½™çš„å•ä¸ªå›¾ç‰‡
    for paths in hash_buckets.values():
        if paths and len(paths) == 1:
            groups_new[group_id] = paths
            group_id += 1
    
    new_time = time.time() - start_time
    print(f"æ–°ç®—æ³•å®Œæˆï¼Œè€—æ—¶: {new_time:.2f}ç§’")
    print(f"æ‰¾åˆ° {len(groups_new)} ä¸ªå›¾ç‰‡ç»„")
    
    # æ€§èƒ½å¯¹æ¯”
    print("\n" + "=" * 60)
    print("æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print("=" * 60)
    print(f"æ—§ç®—æ³•è€—æ—¶: {old_time:.2f} ç§’")
    print(f"æ–°ç®—æ³•è€—æ—¶: {new_time:.2f} ç§’")
    print(f"æ€§èƒ½æå‡: {old_time/new_time:.1f} å€")
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    old_duplicates = sum(1 for group in groups_old.values() if len(group) > 1)
    new_duplicates = sum(1 for group in groups_new.values() if len(group) > 1)
    
    print(f"\nç»“æœéªŒè¯:")
    print(f"æ—§ç®—æ³•æ‰¾åˆ°é‡å¤ç»„: {old_duplicates}")
    print(f"æ–°ç®—æ³•æ‰¾åˆ°é‡å¤ç»„: {new_duplicates}")
    
    if old_duplicates == new_duplicates:
        print("âœ… ä¸¤ç§ç®—æ³•ç»“æœä¸€è‡´")
    else:
        print("âŒ ç®—æ³•ç»“æœä¸ä¸€è‡´ï¼Œéœ€è¦æ£€æŸ¥")
    
    return old_time, new_time

if __name__ == "__main__":
    try:
        old_time, new_time = test_performance()
        
        if new_time < old_time / 2:  # è‡³å°‘å¿«2å€
            print("\nğŸ‰ æ€§èƒ½ä¼˜åŒ–æˆåŠŸï¼")
        else:
            print("\nâš ï¸  æ€§èƒ½ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾")
            
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()